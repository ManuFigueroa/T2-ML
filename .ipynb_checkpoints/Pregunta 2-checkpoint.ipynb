{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 2. Análisis de opiniones sobre películas.\n",
    "a) En primer lugar hay que descargar los datos de la URL asignada y luego se guardan en los archivos train_data2.csv y test_data2.csv. \n",
    "\n",
    "Luego se abren los archivos y se crea un dataframe para los conjuntos de datos de entrenamiento (train) y prueba (test).\n",
    "\n",
    "La primera columna de los sets de datos corresponde al sentimiento (Sentiment). Si es \"-1\", entonces el comentario es negativo. Si es \"+1\" entonces el comentario será positivo. Esto se pudo comprobar leyendo un extracto del dataframe. \n",
    "\n",
    "La segunda columna será el review de la persona con respecto a una película."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3554, 2)\n",
      "(3554, 2)\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "train_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.train\"\n",
    "test_data_url = \"http://www.inf.utfsm.cl/~jnancu/stanford-subset/polarity.dev\"\n",
    "train_data_f = urllib.urlretrieve(train_data_url, \"train_data2.csv\")\n",
    "test_data_f = urllib.urlretrieve(test_data_url, \"test_data2.csv\")\n",
    "'''\n",
    "\n",
    "\n",
    "ftr = open(\"train_data2.csv\", \"r\")\n",
    "fts = open(\"test_data2.csv\", \"r\")\n",
    "rows = [line.split(\" \",1) for line in ftr.readlines()]\n",
    "train_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "train_df['Sentiment'] = pd.to_numeric(train_df['Sentiment'])\n",
    "rows = [line.split(\" \",1) for line in fts.readlines()]\n",
    "test_df = pd.DataFrame(rows, columns=['Sentiment','Text'])\n",
    "test_df['Sentiment'] = pd.to_numeric(test_df['Sentiment'])\n",
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se tiene que tanto el conjunto de entrenamiento como el de pruebas tienen igual cantidad de registros (3554 filas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Ahora hay que crear una función que entregue una lista de palabras a partir de un determinado texto. A continuación se muestra el código del enunciado, en el cual realiza lematización. Notar que la función ya incluye su debida transformación a lower-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eating cake\n",
      " loved eating cake\n",
      " love eating cake\n",
      " n't love eating cake\n"
     ]
    }
   ],
   "source": [
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "def word_extractor_lemmatizer(text, del_stopwords=True):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    if del_stopwords == True:\n",
    "        commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ wordlemmatizer.lemmatize(word.lower()) for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if del_stopwords==True:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        else:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "\n",
    "print word_extractor_lemmatizer(\"I love to eat cake\")\n",
    "print word_extractor_lemmatizer(\"I love eating cake\")\n",
    "print word_extractor_lemmatizer(\"I loved eating the cake\")\n",
    "print word_extractor_lemmatizer(\"I do not love eating cake\")\n",
    "print word_extractor_lemmatizer(\"I don't love eating cake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código es el modificado que incluye el proceso de stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " love eat cake\n",
      " n't love eat cake\n"
     ]
    }
   ],
   "source": [
    "def word_extractor(text, del_stopwords=True):\n",
    "    stemmer = PorterStemmer()\n",
    "    if del_stopwords==True:\n",
    "        commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text)#substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ stemmer.stem(word.lower()) for word in word_tokenize(text.decode('utf-8', 'ignore')) ]\n",
    "    for word in wordtokens:\n",
    "        if del_stopwords==True:\n",
    "            if word not in commonwords:\n",
    "                words+=\" \"+word\n",
    "        else:\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "\n",
    "print word_extractor(\"I love to eat cake\")\n",
    "print word_extractor(\"I love eating cake\")\n",
    "print word_extractor(\"I loved eating the cake\")\n",
    "print word_extractor(\"I do not love eating cake\")\n",
    "print word_extractor(\"I don't love eating cake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa una gran diferencia ya que, para la función que incluye lematización, se puede ver a simple vista que solo se eliminaron las stop-words. En cambio, para la función con stemming, las primeras cuatro frases quedan como \"love eat cake\", ya que las palabras \"loved\" y \"eating\" se redujeron a su raiz \"love\" y \"eat\" respectivamente.\n",
    "\n",
    "Probando con otras frases..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'm play playstat 4 everi week\n",
      " play playstat 4 everi week\n",
      " learn lot machin learn class\n",
      " learn lot machin learn class\n"
     ]
    }
   ],
   "source": [
    "print word_extractor(\"I'm playing PlayStation 4 every week\")\n",
    "print word_extractor(\"I play PlayStation 4 every week\")\n",
    "\n",
    "print word_extractor(\"I learned a lot in the Machine Learning class\")\n",
    "print word_extractor(\"I learn a lot from the Machine Learning classes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los ejemplos anteriores, se ve que para las dos primeras frases la función trata al nombre propio \"PlayStation\" como una palabra más, y le borra el sufijo \"ion\", quedando \"playstat\". \n",
    "\n",
    "Para las otras dos frases, cada una entrega un mensaje distinto. La primera comunica que el sujeto aprendió harto de la clase de Machine Learning. En la segunda frase, el sujeto informa que aprende harto de las clases de Machine Learning. Aún así, luego del proceso de stemming ambas frases quedan iguales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) La función word_extractor_lemmatizer() trata las palabras por lematización y fue realizada anteriormente. A continuación se muestran los últimos ejemplos anteriores utilizando lematización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'm playing playstation 4 every week\n",
      " play playstation 4 every week\n",
      " learned lot machine learning class\n",
      " learn lot machine learning class\n"
     ]
    }
   ],
   "source": [
    "print word_extractor_lemmatizer(\"I'm playing PlayStation 4 every week\")\n",
    "print word_extractor_lemmatizer(\"I play PlayStation 4 every week\")\n",
    "\n",
    "print word_extractor_lemmatizer(\"I learned a lot in the Machine Learning class\")\n",
    "print word_extractor_lemmatizer(\"I learn a lot from the Machine Learning classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Técnicamente, el proceso de stemming lo que hace es cortar el final de las palabras sin importar el significado de la palabra según el contexto. Lemmatization (o lematización) es un proceso mas complejo, ya que utiliza una búsqueda en un vocabulario y realiza un análisis morfológico de las palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Ahora hay que realizar una representación vectorial de los textos de entrenamiento y pruebas. En primer lugar, los textos se pasan por el proceso de lematización, eliminando también las *stop words*. Luego, se inicializa la función *CountVectorizer* con n=1, de tal forma que cada palabra sumará 1. Esto es útil cuando se suma el total de la presencia de una palabra. Estos vectores quedan guardados en *features_train* y *features_test* para los sets de entrenamiento y prueba respectivamente.\n",
    "\n",
    "Luego se guarda la etiqueta de cada review. Cuando el campo Sentiment es -1 y se suma con 1, queda en 0. Si el mismo campo es 1 y se suma con 1, luego se divide por 2 y queda 1. Entonces, las etiquetas quedarán guardadas como 0 cuando la review es negativa y 1 cuando la review es positiva. Estos datos quedan guardados en las variables *labels_train* y *labels_test*.\n",
    "\n",
    "Luego se guardan las palabras en el vector *vocab*, y su frecuencia de aparición en el vector *dist*. Esto es usado más abajo para determinar cuáles son las palabras mas frecuentes tanto en el set de entrenamiento como en el de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def vectorial(modo='lemmatization', del_stopwords=True, print_top10=0):\n",
    "    \n",
    "    if modo=='lemmatization':\n",
    "        if del_stopwords==True:\n",
    "            texts_train = [word_extractor_lemmatizer(text) for text in train_df.Text]\n",
    "            texts_test = [word_extractor_lemmatizer(text) for text in test_df.Text]\n",
    "        else:\n",
    "            texts_train = [word_extractor_lemmatizer(text, False) for text in train_df.Text]\n",
    "            texts_test = [word_extractor_lemmatizer(text, False) for text in test_df.Text]\n",
    "    if modo == 'stemming':\n",
    "        if del_stopwords==True:\n",
    "            texts_train = [word_extractor(text) for text in train_df.Text]\n",
    "            texts_test = [word_extractor(text) for text in test_df.Text]\n",
    "        else:\n",
    "            texts_train = [word_extractor(text, False) for text in train_df.Text]\n",
    "            texts_test = [word_extractor(text, False) for text in test_df.Text]\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1), binary='False')\n",
    "    vectorizer.fit(np.asarray(texts_train))\n",
    "    features_train = vectorizer.transform(texts_train)\n",
    "    features_test = vectorizer.transform(texts_test)\n",
    "    labels_train = np.asarray((train_df.Sentiment.astype(float)+1)/2.0)\n",
    "    labels_test = np.asarray((test_df.Sentiment.astype(float)+1)/2.0)\n",
    "\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "    dist_train=list(np.array(features_train.sum(axis=0)).reshape(-1,))\n",
    "    if print_top10 == 1:\n",
    "        rank = []\n",
    "        for tag, count in zip(vocab, dist_train):\n",
    "            rank.append((count, tag))\n",
    "\n",
    "        rank.sort()\n",
    "        rank[:] = rank[::-1]\n",
    "        \n",
    "        print \"MODO:\", modo, \"ELIMINA stopwords:\", del_stopwords, \"\\n\"\n",
    "        \n",
    "        print \"Palabras más frecuentes en el set de entrenamiento\"\n",
    "        for i in range(0,10):\n",
    "            print \"Frecuencia: %d, palabra: %s\"% (rank[i][0], rank[i][1])\n",
    "\n",
    "        vocab = vectorizer.get_feature_names()\n",
    "        dist_test=list(np.array(features_test.sum(axis=0)).reshape(-1,))\n",
    "\n",
    "        rank = []\n",
    "        for tag, count in zip(vocab, dist_test):\n",
    "            rank.append((count, tag))\n",
    "\n",
    "        rank.sort()\n",
    "        rank[:] = rank[::-1]\n",
    "        print \"\\nPalabras más frecuentes en el set de prueba\"\n",
    "        for i in range(0,10):\n",
    "            print \"Frecuencia: %d, palabra: %s\"% (rank[i][0], rank[i][1])\n",
    "    return features_train, labels_train, features_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODO: lematize ELIMINA stopwords: True \n",
      "\n",
      "Palabras más frecuentes en el set de entrenamiento\n",
      "Frecuencia: 566, palabra: film\n",
      "Frecuencia: 481, palabra: movie\n",
      "Frecuencia: 246, palabra: one\n",
      "Frecuencia: 245, palabra: like\n",
      "Frecuencia: 224, palabra: ha\n",
      "Frecuencia: 183, palabra: make\n",
      "Frecuencia: 176, palabra: story\n",
      "Frecuencia: 163, palabra: character\n",
      "Frecuencia: 145, palabra: comedy\n",
      "Frecuencia: 143, palabra: time\n",
      "\n",
      "Palabras más frecuentes en el set de prueba\n",
      "Frecuencia: 558, palabra: film\n",
      "Frecuencia: 540, palabra: movie\n",
      "Frecuencia: 250, palabra: one\n",
      "Frecuencia: 238, palabra: ha\n",
      "Frecuencia: 230, palabra: like\n",
      "Frecuencia: 197, palabra: story\n",
      "Frecuencia: 175, palabra: character\n",
      "Frecuencia: 165, palabra: time\n",
      "Frecuencia: 161, palabra: make\n",
      "Frecuencia: 134, palabra: comedy\n"
     ]
    }
   ],
   "source": [
    "vectorial(print_top10=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) La función *classification_report* de *sklearn* retorna precision, recall y F1 score. Estos indicadores se definen como siguen:\n",
    "* precision: Cantidad de verdaderos positivos dividido por la cantidad de resultados positivos obtenidos (falsos y verdaderos juntos).\n",
    "* recall: Cantidad de verdaderos positivos obtenidos dividido por la cantidad de positivos que se deberían haber obtenido.\n",
    "* F1 score: Corresponde a la media armónica entre precision y recall. Se calcula de la siguiente forma: $F1 Score = 2\\frac{precision * recall}{precison + recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "scores_NAIVE = np.zeros(5)\n",
    "scores_MULTI = np.zeros(5)\n",
    "scores_LOGIT = np.zeros(5)\n",
    "scores_SVM = np.zeros(5)\n",
    "\n",
    "def score_the_model(model,x,y,xt,yt,text):\n",
    "    acc_tr = model.score(x,y)\n",
    "    acc_test = model.score(xt[:-1],yt[:-1])\n",
    "    print \"Training Accuracy %s: %f\"%(text,acc_tr)\n",
    "    print \"Test Accuracy %s: %f\"%(text,acc_test)\n",
    "    print \"Detailed Analysis Testing Results ...\"\n",
    "    print(classification_report(yt, model.predict(xt), target_names=['+','-']))\n",
    "    \n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(yt, model.predict(xt))\n",
    "    if text == 'BernoulliNB':\n",
    "        scores_NAIVE[0] = acc_tr\n",
    "        scores_NAIVE[1] = acc_test\n",
    "        scores_NAIVE[2] = np.mean(precision)\n",
    "        scores_NAIVE[3] = np.mean(recall)\n",
    "        scores_NAIVE[4] = np.mean(fscore)\n",
    "    elif text == 'MultinomialNB':\n",
    "        scores_MULTI[0] = acc_tr\n",
    "        scores_MULTI[1] = acc_test\n",
    "        scores_MULTI[2] = np.mean(precision)\n",
    "        scores_MULTI[3] = np.mean(recall)\n",
    "        scores_MULTI[4] = np.mean(fscore)\n",
    "    elif text == 'LOGISTIC':\n",
    "        scores_LOGIT[0] = acc_tr\n",
    "        scores_LOGIT[1] = acc_test\n",
    "        scores_LOGIT[2] = np.mean(precision)\n",
    "        scores_LOGIT[3] = np.mean(recall)\n",
    "        scores_LOGIT[4] = np.mean(fscore)\n",
    "    elif text == 'SVM':\n",
    "        scores_SVM[0] = acc_tr\n",
    "        scores_SVM[1] = acc_test\n",
    "        scores_SVM[2] = np.mean(precision)\n",
    "        scores_SVM[3] = np.mean(recall)\n",
    "        scores_SVM[4] = np.mean(fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) A continuación se muestra el código que realiza el modelo con el algoritmo **Bernoulli naive Bayes** (binario). Se ejecuta la función *vectorial(modo=..., del_stopwords=..., print_top10=...)* de forma que el retorno de la función cargue los datos de features y labels según el tipo de filtro de palabras que se quiera ocupar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization sin stop words\n",
      "\n",
      "Training Accuracy BernoulliNB: 0.958638\n",
      "Test Accuracy BernoulliNB: 0.738531\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "Muestra aleatoria del conjunto de prueba (test), con sus respectivas probabilidades de naive Bayes\n",
      "\n",
      "[ 0.57295076  0.42704924] . . . jones , despite a definitely distinctive screen presence , just isn't able to muster for a movie that , its title notwithstanding , should have been a lot nastier if it wanted to fully capitalize on its lead's specific gifts .\n",
      "\n",
      "[ 0.01580715  0.98419285] a journey through memory , a celebration of living , and a sobering rumination on fatality , classism , and ignorance .\n",
      "\n",
      "[ 0.90973837  0.09026163] at once overly old-fashioned in its sudsy plotting and heavy-handed in its effort to modernize it with encomia to diversity and tolerance .\n",
      "\n",
      "[ 0.93580412  0.06419588] what could have been right at home as a nifty plot line in steven soderbergh's traffic fails to arrive at any satisfying destination .\n",
      "\n",
      "[ 0.12609298  0.87390702] it's consistently funny , in an irresistible junior-high way , and consistently free of any gag that would force you to give it a millisecond of thought .\n",
      "\n",
      "Lemmatization con stop words\n",
      "\n",
      "Training Accuracy BernoulliNB: 0.955262\n",
      "Test Accuracy BernoulliNB: 0.748663\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.76      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "Stemming sin stop words\n",
      "\n",
      "Training Accuracy BernoulliNB: 0.942881\n",
      "Test Accuracy BernoulliNB: 0.747819\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.74      0.75      1803\n",
      "          -       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "Stemming con stop words\n",
      "\n",
      "Training Accuracy BernoulliNB: 0.938098\n",
      "Test Accuracy BernoulliNB: 0.762173\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.77      0.76      0.77      1803\n",
      "          -       0.76      0.76      0.76      1751\n",
      "\n",
      "avg / total       0.76      0.76      0.76      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import random\n",
    "\n",
    "def do_NAIVE_BAYES(x,y,xt,yt):\n",
    "    model = BernoulliNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"BernoulliNB\")\n",
    "    return model\n",
    "\n",
    "print \"Lemmatization sin stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='lemmatization')\n",
    "model = do_NAIVE_BAYES(features_train, labels_train, features_test, labels_test)\n",
    "print \"Muestra aleatoria del conjunto de prueba (test), con sus respectivas probabilidades de naive Bayes\\n\"\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text\n",
    "\n",
    "print \"Lemmatization con stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='lemmatization', del_stopwords=False)\n",
    "model = do_NAIVE_BAYES(features_train, labels_train, features_test, labels_test)\n",
    "    \n",
    "print \"Stemming sin stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=True)\n",
    "model = do_NAIVE_BAYES(features_train, labels_train, features_test, labels_test)\n",
    "\n",
    "print \"Stemming con stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=False)\n",
    "model = do_NAIVE_BAYES(features_train, labels_train, features_test, labels_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Como resumen de los resultados anteriores para Bernoulli naive Bayes :\n",
    "\n",
    "|                   | Lemmatization sin stop words | Lemmatization con stop words | Stemming sin stop words | Stemming con stop words |\n",
    "|:-----------------:|:----------------------------:|:----------------------------:|:-----------------------:|:-----------------------:|\n",
    "| Training Accuracy |             0.959            |             0.955            |          0.943          |          0.938          |\n",
    "|  Testing Accuracy |             0.739            |             0.748            |          0.748          |          0.762          |\n",
    "|     Precision     |             0.740            |             0.750            |          0.750          |          0.760          |\n",
    "|       Recall      |             0.740            |             0.750            |          0.750          |          0.760          |\n",
    "|      F1-Score     |             0.740            |             0.750            |          0.750          |          0.760          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en las métricas obtenidas (precision, recall y F1-score), se puede observar que todos los modelos generados, tanto con lemmatization como con stemming, no difieren mucho entre ellos. Sin embargo, si se observan los ajustes realizados sin stop words, el método de stemming es mejor que el de lemmatization, ya que presenta métricas de precision, recall y F1-score mejores. Aún así, como las métricas de cada modelo no difieren mucho, convendría usar la forma más rápida.\n",
    "\n",
    "Con respecto a los ejemplos aleatorios, se observa que las probabilidades están muy bien repartidas, ya que la mayoría tiene probabilidad > 0.8 para una clase, y probabilidad < 0.2 para la otra clase. Esto no implica que el modelo clasifique correctamente cada uno de los elementos de prueba. Por ejemplo, al momento de escribir este párrafo se encontraron las siguientes clasificaciones:\n",
    "\n",
    "    1. [ 0.55574848  0.44425152] what doesn't this film have that an impressionable kid couldn't stand to hear ?\n",
    "    2. [ 0.56785683  0.43214317] the actresses may have worked up a back story for the women they portray so convincingly , but viewers don't get enough of that background for the characters to be involving as individuals rather than types .\n",
    "\n",
    "Para ambas reviews se asignaron probabilidades de manera similar, por lo que es difícil decidir a qué clase corresponde cada una. Si se decide ir con la probabilidad mayor, entonces la review 1 quedaría mal clasificada. Esto puede deberse a que la review no es muy explicativa como opinión, sino que corresponde a una pregunta retórica. \n",
    "\n",
    "Además, notar que el training accuracy siempre es mejor que el test accuracy. Esto se debe a que en el set de prueba (test) existen palabras que no están presentes en el set de etrenamiento, y el modelo no se encuentra preparado para evaluar aquellas palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Ahora hay que crear un modelo utilizando **Multinomial naive Bayes** (MNB). A continuación se realiza el mismo procedimiento que el anterior, pero utilizando este algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization sin stop words\n",
      "\n",
      "Training Accuracy MultinomialNB: 0.959482\n",
      "Test Accuracy MultinomialNB: 0.740782\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "Muestra aleatoria del conjunto de prueba (test), con sus respectivas probabilidades de naive Bayes\n",
      "\n",
      "[ 0.39427694  0.60572306] everything about the quiet american is good , except its timing .\n",
      "\n",
      "[ 0.97961921  0.02038079] a decidedly mixed bag .\n",
      "\n",
      "[ 0.93331519  0.06668481] it almost plays like solaris , but with guns and jokes .\n",
      "\n",
      "[ 0.95755788  0.04244212] earnest but heavy-handed .\n",
      "\n",
      "[ 0.20430725  0.79569275] a miraculous movie , i'm going home is so slight , yet overflows with wisdom and emotion .\n",
      "\n",
      "Lemmatization con stop words\n",
      "\n",
      "Training Accuracy MultinomialNB: 0.955543\n",
      "Test Accuracy MultinomialNB: 0.747537\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.75      0.75      1803\n",
      "          -       0.74      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "\n",
      "Stemming sin stop words\n",
      "\n",
      "Training Accuracy MultinomialNB: 0.942319\n",
      "Test Accuracy MultinomialNB: 0.749789\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.75      0.75      1803\n",
      "          -       0.74      0.75      0.75      1751\n",
      "\n",
      "avg / total       0.75      0.75      0.75      3554\n",
      "\n",
      "\n",
      "Stemming con stop words\n",
      "\n",
      "Training Accuracy MultinomialNB: 0.940630\n",
      "Test Accuracy MultinomialNB: 0.759921\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.77      0.76      1803\n",
      "          -       0.76      0.75      0.76      1751\n",
      "\n",
      "avg / total       0.76      0.76      0.76      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def do_MULTINOMIAL(x,y,xt,yt):\n",
    "    model = MultinomialNB()\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"MultinomialNB\")\n",
    "    return model\n",
    "\n",
    "print \"Lemmatization sin stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='lemmatization')\n",
    "model = do_MULTINOMIAL(features_train, labels_train, features_test, labels_test)\n",
    "print \"Muestra aleatoria del conjunto de prueba (test), con sus respectivas probabilidades de naive Bayes\\n\"\n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text\n",
    "\n",
    "print \"Lemmatization con stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='lemmatization', del_stopwords=False)\n",
    "model = do_MULTINOMIAL(features_train, labels_train, features_test, labels_test)\n",
    "    \n",
    "print \"\\nStemming sin stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=True)\n",
    "model = do_MULTINOMIAL(features_train, labels_train, features_test, labels_test)\n",
    "\n",
    "print \"\\nStemming con stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=False)\n",
    "model = do_MULTINOMIAL(features_train, labels_train, features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de los resultados anteriores para Multinomial naive Bayes :\n",
    "\n",
    "|                   | Lemmatization sin stop words | Lemmatization con stop words | Stemming sin stop words | Stemming con stop words |\n",
    "|:-----------------:|:----------------------------:|:----------------------------:|:-----------------------:|:-----------------------:|\n",
    "| Training Accuracy |             0.959            |             0.956            |          0.942          |          0.941          |\n",
    "|  Testing Accuracy |             0.741            |             0.748            |          0.749          |          0.759          |\n",
    "|     Precision     |             0.740            |             0.750            |          0.750          |          0.760          |\n",
    "|       Recall      |             0.740            |             0.750            |          0.750          |          0.760          |\n",
    "|      F1-Score     |             0.740            |             0.750            |          0.750          |          0.760          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual como sucede con Bernoulli naive Bayes, los modelos ajustados con Multinomial naive Bayes son muy similares independiente de la forma en como se procese el texto. Aún así, el método de stemming sigue siendo mejor que lemmatization.\n",
    "\n",
    "Los ejemplos aleatorios obtenidos al momento de la ejecución son los siguientes:\n",
    "\n",
    "    1. [ 0.97587476  0.02412524] the backyard battles you staged with your green plastic army men were more exciting and almost certainly made more sense .\n",
    "    2. [  1.72450066e-04   9.99827550e-01] what makes salton sea surprisingly engrossing is that caruso takes an atypically hypnotic approach to a world that's often handled in fast-edit , hopped-up fashion .\n",
    "    3. [ 0.3719863  0.6280137] . . . would be a total loss if not for two supporting performances taking place at the movie's edges .\n",
    "    4. [ 0.92753966  0.07246034] a sharp and quick documentary that is funny and pithy , while illuminating an era of theatrical comedy that , while past , really isn't .\n",
    "    5. [ 0.14197731  0.85802269] 'frailty \" starts out like a typical bible killer story , but it turns out to be significantly different ( and better ) than most films with this theme .\n",
    "\n",
    "Se puede observar claramente que las probabilidades de la opinión 4 están completamente erroneas, ya que la opinión es positiva. Las probabilidades de la opinión 3 se encuentran más cerca de 0.5 que de 1.0, lo que no es confiable ya que sería difícil decidir a cual clase pertenece. Además, esta opinión es negativa, y la probabilidad mayor corresponde a la clase positiva. El resto de las opiniones se encuentra bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Para esta parte hay que ajustar un modelo de regresión logística regularizado, utilizando la norma $l_2$. En el código del enunciado se realiza un modelo para un listado con distintos valores de regularización C, donde $C=\\frac{1}{\\lambda}$. Luego de observar como cambia el modelo para cada uno de los valores de C, se pudo ver que para los valores más grandes, el modelo tiende a sobre ajustarse (*overfitting*). En cambio, cuando C es más pequeño, el modelo tiene una regularización más fuerte. Es por esta razón que se decidió usar un parámetro de regularización C igual a 0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization sin stop words\n",
      "\n",
      "Training Accuracy LOGISTIC: 0.972988\n",
      "Test Accuracy LOGISTIC: 0.725584\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "Muestra aleatoria del conjunto de prueba (test), con sus respectivas probabilidades:\n",
      "\n",
      "[ 0.82895611  0.17104389] ultimately , jane learns her place as a girl , softens up and loses some of the intensity that made her an interesting character to begin with .\n",
      "\n",
      "[ 0.44390944  0.55609056] stinks from start to finish , like a wet burlap sack of gloom .\n",
      "\n",
      "[ 0.93601007  0.06398993] mckay deflates his piece of puffery with a sour cliche and heavy doses of mean-spiritedness\n",
      "\n",
      "[ 0.22045011  0.77954989] tsai has managed to create an underplayed melodrama about family dynamics and dysfunction that harks back to the spare , unchecked heartache of yasujiro ozu .\n",
      "\n",
      "[ 0.1017992  0.8982008] this is dicaprio's best performance in anything ever , and easily the most watchable film of the year .\n",
      "\n",
      "Lemmatization con stop words\n",
      "\n",
      "Training Accuracy LOGISTIC: 0.968205\n",
      "Test Accuracy LOGISTIC: 0.732902\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.73      0.74      1803\n",
      "          -       0.73      0.74      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "\n",
      "Stemming sin stop words\n",
      "\n",
      "Training Accuracy LOGISTIC: 0.960045\n",
      "Test Accuracy LOGISTIC: 0.737124\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.74      0.74      1803\n",
      "          -       0.73      0.73      0.73      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "\n",
      "Stemming con stop words\n",
      "\n",
      "Training Accuracy LOGISTIC: 0.960045\n",
      "Test Accuracy LOGISTIC: 0.743034\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.74      0.75      1803\n",
      "          -       0.74      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def do_LOGIT(x,y,xt,yt):\n",
    "    start_t = time.time()\n",
    "    '''Cs = [0.01,0.1,10,100,1000]\n",
    "    for C in Cs:'''\n",
    "    '''print \"Usando C= %f\"%C'''\n",
    "    model = LogisticRegression(penalty='l2',C=0.5)\n",
    "    model = model.fit(x, y)\n",
    "    score_the_model(model,x,y,xt,yt,\"LOGISTIC\")\n",
    "    return model\n",
    "        \n",
    "print \"Lemmatization sin stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='lemmatization')\n",
    "model = do_LOGIT(features_train, labels_train, features_test, labels_test)  \n",
    "test_pred = model.predict_proba(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "print \"Muestra aleatoria del conjunto de prueba (test), con sus respectivas probabilidades:\\n\"\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text\n",
    "\n",
    "print \"Lemmatization con stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='lemmatization', del_stopwords=False)\n",
    "model = do_LOGIT(features_train, labels_train, features_test, labels_test)\n",
    "    \n",
    "print \"\\nStemming sin stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=True)\n",
    "model = do_LOGIT(features_train, labels_train, features_test, labels_test)\n",
    "\n",
    "print \"\\nStemming con stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=False)\n",
    "model = do_LOGIT(features_train, labels_train, features_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de los resultados anteriores para Logistic Regression con C=0.5 :\n",
    "\n",
    "|                   | Lemmatization sin stop words | Lemmatization con stop words | Stemming sin stop words | Stemming con stop words |\n",
    "|:-----------------:|:----------------------------:|:----------------------------:|:-----------------------:|:-----------------------:|\n",
    "| Training Accuracy |             0.973            |             0.969            |          0.960          |          0.960          |\n",
    "|  Testing Accuracy |             0.726            |             0.732            |          0.737          |          0.743          |\n",
    "|     Precision     |             0.730            |             0.730            |          0.740          |          0.740          |\n",
    "|       Recall      |             0.730            |             0.730            |          0.740          |          0.740          |\n",
    "|      F1-Score     |             0.730            |             0.730            |          0.740          |          0.740          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa un comportamiento similar a los ajustes anteriores. Las métricas indican que el método de stemming es mejor que lemmatization. El hecho de borrar las stop words puede significar un ahorro en tiempo, pero no necesariamente sirve para obtener mejores resultados. De hecho, los resultados obtenidos con stop words son muy similares a los que se obtienen al quitar aquellas palabras.\n",
    "\n",
    "Los ejemplos aleatorios obtenidos fueron los siguientes:\n",
    "    \n",
    "    1. [ 0.72220716  0.27779284] crudup's screen presence is the one thing that holds interest in the midst of a mushy , existential exploration of why men leave their families .\n",
    "    2. [ 0.02792055  0.97207945] the best didacticism is one carried by a strong sense of humanism , and bertrand tavernier's oft-brilliant safe conduct ( \" laissez-passer \" ) wears its heart on its sleeve .\n",
    "    3. [ 0.32116462  0.67883538] it's not a classic spy-action or buddy movie , but it's entertaining enough and worth a look .\n",
    "    4. [ 0.59770433  0.40229567] steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
    "    5. [ 0.7361555  0.2638445] john carlen's script is full of unhappy , two-dimensional characters who are anything but compelling .\n",
    "\n",
    "Se puede observar que para la mayoría, las probabilidades de cada clase han disminuido en la decena, es decir si antes la probabilidad de una clase era > 0.8, ahora tiende a ser > 0.7. Además, si se comparan estos resultados con la clasificación real, se puede ver que la opinión 4 tiene una mayor probabilidad en la clase negativa, siendo que la opinión es positiva. Esto puede deberse a la presencia de la palabra *hate*, a pesar de que se utiliza para probar un punto positivo en la opinión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Ahora hay que ajustar un modelo support vector machine lineal (Linear SVM). Para ello se usa la función LinearSVC que se encuentra dentro de la librería del mismo nombre. Aquella función recibe un parámetro de penalización C.\n",
    "Luego de probar con los valores de C dados, se decidió usar C=0.1 ya que entrega una mejor precisión (accuracy) para el dataset de prueba. Si el parámetro es más grande, entonces el modelo no se regulariza y tiende a *overfitting*. Esto se puede observar en que la precisión del set de entrenamiento es igual a 1 y la precisión del set de prueba disminuye.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization sin stop words\n",
      "\n",
      "El valor de C que se esta probando: 0.010000\n",
      "Training Accuracy SVM: 0.884637\n",
      "Test Accuracy SVM: 0.715170\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.72      0.72      0.72      1803\n",
      "          -       0.71      0.71      0.71      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 0.100000\n",
      "Training Accuracy SVM: 0.989589\n",
      "Test Accuracy SVM: 0.723614\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.73      0.72      0.73      1803\n",
      "          -       0.72      0.73      0.72      1751\n",
      "\n",
      "avg / total       0.72      0.72      0.72      3554\n",
      "\n",
      "El valor de C que se esta probando: 10.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.702786\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 100.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.698565\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.71      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "El valor de C que se esta probando: 1000.000000\n",
      "Training Accuracy SVM: 1.000000\n",
      "Test Accuracy SVM: 0.697439\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.71      0.69      0.70      1803\n",
      "          -       0.69      0.70      0.70      1751\n",
      "\n",
      "avg / total       0.70      0.70      0.70      3554\n",
      "\n",
      "Muestra aleatoria del conjunto de prueba (test), con su prediccion:\n",
      "\n",
      "0.0 as a rumor of angels reveals itself to be a sudsy tub of supernatural hokum , not even ms . redgrave's noblest efforts can redeem it from hopeless sentimentality .\n",
      "\n",
      "1.0 the characters are complex and quirky , but entirely believable as the remarkable ensemble cast brings them to life .\n",
      "\n",
      "0.0 dramatically lackluster .\n",
      "\n",
      "0.0 mildly amusing .\n",
      "\n",
      "0.0 shatner is probably the funniest person in the film , which gives you an idea just how bad it was .\n",
      "\n",
      "Lemmatization con stop words\n",
      "\n",
      "Training Accuracy SVM: 0.987901\n",
      "Test Accuracy SVM: 0.738249\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.73      0.74      1803\n",
      "          -       0.73      0.75      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "\n",
      "Stemming sin stop words\n",
      "\n",
      "Training Accuracy SVM: 0.981992\n",
      "Test Accuracy SVM: 0.731213\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.74      0.73      0.73      1803\n",
      "          -       0.73      0.73      0.73      1751\n",
      "\n",
      "avg / total       0.73      0.73      0.73      3554\n",
      "\n",
      "\n",
      "Stemming con stop words\n",
      "\n",
      "Training Accuracy SVM: 0.983399\n",
      "Test Accuracy SVM: 0.740501\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.74      0.74      1803\n",
      "          -       0.73      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def do_SVM(x,y,xt,yt,i=False):\n",
    "    Cs = [0.01,0.1,10,100,1000]\n",
    "    if i:\n",
    "        for C in Cs:\n",
    "            print \"El valor de C que se esta probando: %f\"%C\n",
    "            model = LinearSVC(C=C)\n",
    "            model = model.fit(x, y)\n",
    "            score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "    else:\n",
    "        model = LinearSVC(C=0.1)\n",
    "        model = model.fit(x, y)\n",
    "        score_the_model(model,x,y,xt,yt,\"SVM\")\n",
    "    return model\n",
    "\n",
    "print \"Lemmatization sin stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='lemmatization')\n",
    "model = do_SVM(features_train,labels_train,features_test,labels_test,True)\n",
    "test_pred = model.predict(features_test)\n",
    "spl = random.sample(xrange(len(test_pred)), 5)\n",
    "print \"Muestra aleatoria del conjunto de prueba (test), con su prediccion:\\n\"\n",
    "for text, sentiment in zip(test_df.Text[spl], test_pred[spl]):\n",
    "    print sentiment, text\n",
    "\n",
    "print \"Lemmatization con stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='lemmatization', del_stopwords=False)\n",
    "model = do_SVM(features_train, labels_train, features_test, labels_test)\n",
    "    \n",
    "print \"\\nStemming sin stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=True)\n",
    "model = do_SVM(features_train, labels_train, features_test, labels_test)\n",
    "\n",
    "print \"\\nStemming con stop words\\n\"\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=False)\n",
    "model = do_SVM(features_train, labels_train, features_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de los resultados anteriores para SVM con C=0.1 :\n",
    "\n",
    "|                   | Lemmatization sin stop words | Lemmatization con stop words | Stemming sin stop words | Stemming con stop words |\n",
    "|:-----------------:|:----------------------------:|:----------------------------:|:-----------------------:|:-----------------------:|\n",
    "| Training Accuracy |             0.989            |             0.987            |          0.981          |          0.983          |\n",
    "|  Testing Accuracy |             0.723            |             0.738            |          0.731          |          0.741          |\n",
    "|     Precision     |             0.720            |             0.740            |          0.730          |          0.740          |\n",
    "|       Recall      |             0.720            |             0.740            |          0.730          |          0.740          |\n",
    "|      F1-Score     |             0.720            |             0.740            |          0.730          |          0.740          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lo anterior se observa que las métricas obtenidas para el modelo entrenado con el texto procesado en stemming son mejores que las métricas del modelo con lemmatization.\n",
    "\n",
    "A continuación se muestran las predicciones obtenidas para un conjunto aleatorio del set de prueba:\n",
    "\n",
    "    1. 1.0 highlighted by a gritty style and an excellent cast , it's better than one might expect when you look at the list of movies starring ice-t in a major role .\n",
    "    2. 1.0 fessenden's narrative is just as much about the ownership and redefinition of myth as it is about a domestic unit finding their way to joy .\n",
    "    3. 1.0 if you collected all the moments of coherent dialogue , they still wouldn't add up to the time required to boil a four- minute egg .\n",
    "    4. 0.0 a yawn-provoking little farm melodrama .\n",
    "    5. 0.0 if you're not the target demographic . . . this movie is one long chick-flick slog .\n",
    "    \n",
    "La predicción 1 corresponde a la clase de opiniones positivas, y la predicción 0 corresponde a la predicción negativa. De las predicciones anteriores se puede observar que todas están correctamente clasificadas a excepción de la opinión número tres. Esto puede deberse a que el crítico que escribió aquella review hizo uso de sarcasmo para dar su opinión, por lo que el modelo entrenado no está preparado para predecir aquello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy BernoulliNB: 0.938098\n",
      "Test Accuracy BernoulliNB: 0.762173\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.77      0.76      0.77      1803\n",
      "          -       0.76      0.76      0.76      1751\n",
      "\n",
      "avg / total       0.76      0.76      0.76      3554\n",
      "\n",
      "Training Accuracy MultinomialNB: 0.940630\n",
      "Test Accuracy MultinomialNB: 0.759921\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.76      0.77      0.76      1803\n",
      "          -       0.76      0.75      0.76      1751\n",
      "\n",
      "avg / total       0.76      0.76      0.76      3554\n",
      "\n",
      "Training Accuracy LOGISTIC: 0.960045\n",
      "Test Accuracy LOGISTIC: 0.743034\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.74      0.75      1803\n",
      "          -       0.74      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n",
      "Training Accuracy SVM: 0.983399\n",
      "Test Accuracy SVM: 0.740501\n",
      "Detailed Analysis Testing Results ...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          +       0.75      0.74      0.74      1803\n",
      "          -       0.73      0.74      0.74      1751\n",
      "\n",
      "avg / total       0.74      0.74      0.74      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Graficos\n",
    "## Todos con stemming con stop words\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=False)\n",
    "model = do_NAIVE_BAYES(features_train, labels_train, features_test, labels_test)\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=False)\n",
    "model = do_MULTINOMIAL(features_train, labels_train, features_test, labels_test)\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=False)\n",
    "model = do_LOGIT(features_train, labels_train, features_test, labels_test)\n",
    "features_train, labels_train, features_test, labels_test = vectorial(modo='stemming', del_stopwords=False)\n",
    "model = do_SVM(features_train, labels_train, features_test, labels_test)\n",
    "#al llamar a las técnicas se llenan los arreglos de score con datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwcAAAEZCAYAAADCG1mNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJCXDgSRJkiTAcCBJkiQpfQB5BPC6MkXYNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15a3a0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#en esta celda ya están cargados los arreglos por correr la celda anterior\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10, 4), dpi=300)\n",
    "index = np.arange(4)\n",
    "bar_width = 0.15\n",
    "opacity = 1\n",
    "\n",
    "\n",
    "#accuracy test\n",
    "plt.bar(index + bar_width, [scores_NAIVE[1],scores_MULTI[1],scores_LOGIT[1],scores_SVM[1]], bar_width,\n",
    "        alpha=opacity, color='deeppink', label='Accuracy Test')\n",
    "#Precision\n",
    "plt.bar(index + 2*bar_width, [scores_NAIVE[2],scores_MULTI[2],scores_LOGIT[2],scores_SVM[2]], bar_width,\n",
    "        alpha=opacity, color='darkorchid', label='Precision')\n",
    "#Recall\n",
    "plt.bar(index + 3*bar_width, [scores_NAIVE[3],scores_MULTI[3],scores_LOGIT[3],scores_SVM[3]], bar_width,\n",
    "        alpha=opacity, color='darkgoldenrod', label='Recall')\n",
    "#F1-Score\n",
    "rects5 = plt.bar(index + 4*bar_width, [scores_NAIVE[4],scores_MULTI[4],scores_LOGIT[4],scores_SVM[4]], bar_width,\n",
    "        alpha=opacity, color='b', label='F1-Score')\n",
    "\n",
    "plt.xlabel('Metodos de Clasificacion')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Stemming con stop words')\n",
    "plt.xticks(index + bar_width*3, ('Bernoulli Naive', 'Multinomial Naive', 'Logistic Regression', 'Linear SVM'))\n",
    "ax.set_ylim([0.7,0.8])\n",
    "lgd = plt.legend(bbox_to_anchor=(1.05, 1), loc=2,fancybox=True)\n",
    "\n",
    "fig.savefig('stemming con stop.png',bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se pudo observar en las métricas anteriormente, numéricamente las métricas son muy similares, pero al limitar el eje Y entre 0.7 y 0.8, se observa que Bernoulli naive Bayes es mejor que regresión logistica y SVM lineal. Además, se puede observar claramente lo similares que son las métricas para un mismo modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
